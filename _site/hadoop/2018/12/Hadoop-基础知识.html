<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>[Hadoop]基础知识 - xlin的个人博客</title>
    <meta name="author"  content="xlinboy">
    <meta name="description" content="[Hadoop]基础知识">
    <meta name="keywords"  content="Hadoop">
    <!-- Open Graph -->
    <meta property="og:title" content="[Hadoop]基础知识 - xlin的个人博客">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/hadoop/2018/12/Hadoop-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html">
    <meta property="og:description" content="记录编程的学习笔记">
    <meta property="og:site_name" content="xlin的个人博客">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="/assets/css/gitalk.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-124506309-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-124506309-1');
    </script>

    
</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="false"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
            <li><a href="/categories.html">categories</a></li>
            
        </ul>
    </nav>
</header>


  <header class="g-banner post-header post-pattern-circuitBoard bgcolor-default " data-theme="default">
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="http://localhost:4000/tags#Hadoop" class="post-tag">Hadoop</a>
          
        
      </div>
      <h1>[Hadoop]基础知识</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i><a href="http://localhost:4000" target="_blank" rel="author">xlinboy</a></></span>
        <time class="post-meta-item" datetime="18-12-16"><i class="iconfont icon-date"></i>16 Dec 2018</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('../../../assets/img/hadoop-logo.jpg') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    
    <h2 class="post-subtitle">Hadoop权威指南</h2>
    

    <article class="markdown-body">
      <h3 id="1-hadoop">1 Hadoop</h3>

<p>Hadoop可以看做将MapReduce计算转移到存储有部分数据的各台机器上。</p>

<p><strong>三大设计目标：</strong></p>

<ol>
  <li>为只需要几分钟或几小时就能完成的任务提供服务。</li>
  <li>运用于同一个内部有高速网络连接的数据中心内。</li>
  <li>数据中心内的计算机都是可靠的、专门的硬件</li>
</ol>

<h4 id="11-普通分析">1.1 普通分析</h4>

<p>并行处理程序进行数据分析：</p>
<ul>
  <li>将任务划分成大小相同的作业。</li>
  <li>合并各个独立进程的运行结果，可能还需要进行额外处理。</li>
  <li>受限单台计算机的处理能力。</li>
</ul>

<h4 id="12-使用hadoop来分析数据">1.2 使用Hadoop来分析数据</h4>

<p>MapReduce任务过程分两个阶段：都以键-值对做为输入和输出</p>
<ul>
  <li>map阶段：数据准备
    <ul>
      <li>提取想要的字段，以及去除已损数据；</li>
      <li>输入的是NCDC原始数据。默认为文本格式</li>
      <li>键(key)是文件中的行偏移量，值(value)为文本格式的数据</li>
    </ul>
  </li>
  <li>reduce阶段：数据处理
    <ul>
      <li>比如：这个处理基于键-值对进行排序和分组</li>
    </ul>
  </li>
</ul>

<p> Unix管线模拟整个MapReduce的逻辑数据流
<img src="https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/6Imgg309g2.png" alt="mark" /></p>

<p>hadoop将作业分成若干个任务(task)来执行：</p>
<ul>
  <li>map任务</li>
  <li>reduce任务</li>
</ul>

<blockquote>
  <p>由YARN进行调度，第一个分片都会构建一个map任务</p>
</blockquote>

<p>一个Reduce任务的MapReduce数据流：</p>

<p><img src="https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/97i6I30LmC.png" alt="mark" /></p>

<p>如果有多个map任务就会针对输出进行分区(partintion),即为每一个reduce任务建一个分区</p>

<p>多个任务的数据流图：shuffle</p>

<p><img src="https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/hi48HeLbJf.png" alt="mark" /></p>

<p>数据处理可以完全并行（无需混洗）</p>

<p><img src="https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/hi48HeLbJf.png" alt="mark" /></p>

<h4 id="combiner函数">combiner函数</h4>

<p>​    可以针对map任务的输出指定一个 combiner ,combiner 函数的输出作为reduce 函数的输入。</p>

<h2 id="2-hdfs">2 HDFS</h2>
<p>HDFS是Hadoop的文件系统，实际上Hadoop是一个综合性的文件系统抽象。</p>

<h4 id="21-数据块">2.1 数据块</h4>

<p>HDFS块(block)默认为128M(以前的版本默认是64M)。与面向单一磁盘文件不同的是，HDFS中小于一个块大小的文件不会占据整个空间。</p>

<blockquote>
  <p>HDFS的块比磁盘的块大，目的是为了最小化寻址开销。</p>
</blockquote>

<p><strong>优点：</strong></p>

<ol>
  <li>文件大小可以大于网络中任意一个磁盘容量</li>
  <li>使用抽象块而非整个文件作为存储单元，简化了存储子系统的设计</li>
  <li>适合用于数据备份</li>
</ol>

<h4 id="22-namenode和datanode">2.2 namenode和datanode</h4>

<p>客户端(client)：代表用户通过与namenode和datanode交互访问整个文件系统。</p>

<h5 id="221-namenode-管理节点">2.2.1 namenode (管理节点)</h5>

<p>  管理着整个HDFS文件系统的元数据。记录每个文件中各个块所在的数据节点信息，它并不永久保存块的位置信息，因为这些信息会在系统启动时根据数据节点信息重建。</p>

<ol>
  <li>初始化:
    <ul>
      <li>生成fsimage 和 blockpool 编号</li>
    </ul>
  </li>
  <li>启动：
    <ul>
      <li>把残留的edits和fsiamge合并</li>
      <li>datanode向namenode进行汇报（安全模式），元数据的校验，验证datanode是否正常启动之后 ，datanode会和namenode保持心跳的交换。 默认保持10S的心中信息</li>
    </ul>
  </li>
</ol>

<p>元数据大概分两个层次：</p>
<ul>
  <li>Namespace管理层，负责管理文件系统中的树状目录结构以及文件与数据块的映射关系
    <ul>
      <li>Namespace管理的元数据除内存常驻外，也会周期Flush到持久化设备上FsImage文件</li>
    </ul>
  </li>
  <li>BolcksMap块管理层，负责管理文件系统中文件的物理块与实际存储位置的映射关系。
    <ul>
      <li>BlocksMap元数据只在内存中存在</li>
    </ul>
  </li>
</ul>

<p>​       当NameNode发生重启，首先从持久化设备中读取FsImage构建Namespace，之后根据DataNode的汇报信息重新构造BlocksMap。</p>

<p>HDFS对namenode两种容错机制:</p>
<ol>
  <li>备份那些组成文件系统元数据持久状态的文件。Hadoop可以通过配置使namenode在多个文件系统上保存元数据的持久状态。</li>
  <li>辅助的namenode(Second NameNode)，但它不能作namenode。它会定期合并编辑日志(edits log)与命名空间镜像(fsimage),以防止日志过大。这个辅助namenode一般会在另一台单独的物理计算机上运行，因为它需要占用大量CPU时间，并且需要与namenode一样多的内存来执行合并操作。但是，辅助namenode保存的状态滞后于主节点，所以在主节点全部失效时，难免会丢失部分数据。</li>
</ol>

<h6 id="namenode安全模式safenode">namenode安全模式(safenode)</h6>
<ul>
  <li>namenode在刚启动时，内存中只有文件和文件的块id及副本数量，不知道datanode在哪里。</li>
  <li>namenode需要等待所有datanode向他汇报自身持有的块信息，namenode才能在元数据中补全文件块信息中的位置信息。</li>
  <li>只有当namenode长到99.8%的块位置信息，才会即出安全模式，正常对外提供服务。</li>
</ul>

<h4 id="222-datanode-工作节点">2.2.2 datanode (工作节点)</h4>

<p>  是文件系统的工作节点。它们根据需要存储并检索数据块（受客户端或namenode调试），并定期向namenode发送它们所存储的块的列表。</p>

<p>datanode为什么要定期汇报自身block信息:</p>

<ul>
  <li>当集群中某些副本失效时，集群如何恢复block初始副本数量的问题。</li>
</ul>

<p>datanode上保存文件，是以block的形式保存。block默认大小为128M。块的大小根据上传文件的大小/block的大小。</p>

<p>data保存时，会有一个副本机制，默认是会为每个文件保存3份(dfs.replication)。</p>

<p><strong>block的分配原则(网络距离越近，优先程度越高)</strong>:</p>

<ol>
  <li>和客户端在同一个机架的节点</li>
  <li>和客户端在不同机架的节点</li>
  <li>和客户端在同一个机架的其他一个节点</li>
  <li>负载均衡</li>
</ol>

<p><strong>datanode故障无法与namenode通信</strong>:</p>
<ol>
  <li>namenode不会立即判断datanode死亡，要经过一段时间，这段时间称作超时时长。</li>
</ol>

<p><strong>datanode为什么要用block的形式来存放数据？</strong></p>

<ol>
  <li>大文件存放无压力</li>
  <li>高可用</li>
  <li>blocke有规律的存储和读取</li>
</ol>

<p><strong>鉴于block保存机制，使用hdfs来存放文件的时候，需要注意些什么？</strong></p>
<ul>
  <li>hdfs更适合放大文件。</li>
  <li>3ktxt，block形式存放，占用空间是依然是3k，但是会占用一个block。</li>
</ul>

<p><code class="highlighter-rouge">hdfs dfsadmin -report</code> ：可以通过此命令查看块信息</p>

<h4 id="23-hdfs高可用">2.3 HDFS高可用</h4>

<p>默认没有高可用机制。可以通过配置实现。</p>

<p>活动-备用(active-standby)namenode。当活动namenode失效，备用namenode就会接管它的任务，并开始服务于客户端的请求，不会有任务明显中断。</p>
<ul>
  <li>namenode之间需要通过高可以用共享存储编辑日志的共享。</li>
  <li>datanode需要同时向两个namenode发送数据块处理报告。数据块的映射信息存储在namenode的内存中。</li>
  <li>辅助namenode的角色被备用namenode所包含，备用namenode为活动namenode命名空间设置周期性检查点。</li>
</ul>

<h5 id="231-故障切换与规避">2.3.1 故障切换与规避</h5>

<ul>
  <li>故障转移控制器(failover controller):  管理将活动的namenode转移为备用namenode的转换过程。
    <ul>
      <li>默认使用ZooKeeper来确保有且仅有一个活动namenode。</li>
      <li>第一个namenode运行着一个轻量级的故障转移控制器，监视宿主机namenode是否失效，并在namenode失效时进行故障切换。</li>
    </ul>
  </li>
  <li>
    <p>平稳故障转移(graceful failover):  故障转移器可以组织两个namenode有序地切换。</p>
  </li>
  <li>规避(fencing): 以确保先前活动的namenode不会执行危害系统并导致系统崩溃的操作。</li>
</ul>

<h4 id="24-命令行接口">2.4 命令行接口</h4>

<ul>
  <li>
    <p>fs.defaultFS, 设置为 hdfs://localhost/,用于设置hadoop的默认文件系统。HDFS的守护程序通过该属性来确定HDFS namenode的主机和端口。</p>
  </li>
  <li>
    <p>fs.replication, HDFS默认设置将文件系统的复本。设为1时，单独一个datanode上运行，HDFS将无法复制到3个datanode。设置为5时，如果节点只有3个，它还是只会复制为3份。</p>
  </li>
</ul>

<h5 id="241-文件系统的基本操作">2.4.1 文件系统的基本操作</h5>

<p>上传文件</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bin/hadoop fs -put tmp.txt hdfs://hadoop1:9001/
</code></pre></div></div>
<p>下载文件</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bin/hadoop fs -get hdfs://hadoop1:9001/tmp.txt
</code></pre></div></div>

<p>从本地将一个文件复制到HDFS:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>默认域名在core-site.xml中的defaultFS指定
bin/hadoop fs -copyFromLocal input/core-site.xml hdfs://hadoop1/user/root/core.xml

省略, hdfs://hadoop1，因为该项在core-site.xml指定。
bin/hadoop fs -copyFromLocal input/core-site.xml /user/root/core.xml

相对路径(默认为/user/root)
bin/hadoop fs -copyFromLocal input/core-site.xml core.xml
</code></pre></div></div>
<p>将文件复制回本地，并查检是否一致</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
bin/hadoop fs -copyToLocal core.xml input/core-site.copy.xml

md5sum input/core-site.copy.xml input/core-site.xml
</code></pre></div></div>
<p>新建一个目录:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bin/hadoop fs -mkdir books
默认在/user/root(用户)目录下
</code></pre></div></div>
<p>显示/user/root下的目录结构</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hadoop fs -ls .
</code></pre></div></div>
<h4 id="242-hdfs权限">2.4.2 HDFS权限</h4>

<p>启动权限 dfs.permissions.enabled属性</p>

<p>超级用户是namenode进程的标识。对于超级用户，系统不会执行任何检查。</p>

<h3 id="3-数据流">3 数据流</h3>

<h4 id="31-文件读取java-api式">3.1 文件读取（JAVA API式）</h4>

<p>HDFS、namenode、datanode之间的数据流交互:</p>

<p><img src="https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/mhmdc20LkG.png" alt="mark" /></p>

<ol>
  <li>client通过<code class="highlighter-rouge">FileSystem</code>对象(对于<code class="highlighter-rouge">hdfs</code>， <code class="highlighter-rouge">DistributedFileSystem</code>)的open()方法打开文件。</li>
  <li><code class="highlighter-rouge">DistributedFileSystem </code>通过远程调用（RPC）来调用namenode，确定文件起始块的位置。对于每一个块, namenode返回该块副本的datanode地址。datanode根据与client的距离来排序。</li>
  <li>对<code class="highlighter-rouge">DistributedFileSystem</code>类返回的<code class="highlighter-rouge">FSDataInputStream</code>(文件定位输入流)类，调用<code class="highlighter-rouge">read()</code>方法。根据namenode返回的该块datanode地址，链接最近的文件中第一个块所在的datanode。</li>
  <li>反复调用<code class="highlighter-rouge">read()</code>方法，可以将数据从datanode传输到客户端</li>
  <li>到达块的末端时，<code class="highlighter-rouge">DFSInputStream</code>(<code class="highlighter-rouge">FSDataInputStream</code>类封装的对象)关闭与datanode的链接，然后寻找下一个块的最佳datanode。</li>
  <li>client客户端读取完成，FSDataInputStream调用close()方法</li>
</ol>

<blockquote>
  <p>如果DFSInputStream在与datanode通迅时遇到错误，会尝试从这个块的另外一个邻近datanode读取数据。并记住故障的datanode, 保证后续不会反复读取该节点。</p>
</blockquote>

<p><strong>客户端可以直接连接到datanode检索数据，且 namenode告知client每个块所在最佳的datanode。namenode只需响应位置的请求，而无需响应数据请求。</strong></p>

<h4 id="32-网络拓扑与hadoop">3.2 网络拓扑与Hadoop</h4>

<p>带宽依次递减：</p>
<ol>
  <li>同一节点上的进程</li>
  <li>同一机架上的不同节点</li>
  <li>同一数据中心不同机架上的节点</li>
  <li>不同数据中心中的节点</li>
</ol>

<p>例如, 假设有数据中心d1机架r1中的节点n1。该节点可以表示为/d1/r1/n1。上述四种距离描述:</p>
<ul>
  <li>distance(/d1/r1/n1, d1/r1/n1)=0</li>
  <li>distance(/d1/r1/n1, d1/r1/d1)=2</li>
  <li>distance(/d1/r1/n1, d1/r1/d1)=4</li>
  <li>distance(/d1/r1/n1, d1/r1/d1)=6</li>
</ul>

<p><img src="https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/1k5G7mkIcf.png" alt="mark" /></p>

<h2 id="文件写入">文件写入</h2>
<p>如果新建一个文件，把数据写入，最后关闭该文件。</p>

<p><img src="https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/f994L79J3J.png" alt="mark" /></p>

<ol>
  <li>client通过对<code class="highlighter-rouge">DistributedFileSystem</code>对象调用<code class="highlighter-rouge">reate()</code>来新建文件</li>
  <li><code class="highlighter-rouge">DistributedFileSystem</code>对namenode创建一个RPC调用，在文件系统的命名空间中新建一个文件，此时文件还没有相应的数据块</li>
  <li>namenode执行各种不同的检查以确保这个文件不存在以及client新建该文件的权限。
    <ul>
      <li>如果检查通过，namenode就会创建新文件并记录；否则，文件创建失败并向client抛出IOException异常。</li>
      <li><code class="highlighter-rouge">DistributedFileSystem</code>向客户端返回一个<code class="highlighter-rouge">FSDataOutputStream</code>对象</li>
      <li>由此 client 开始写入数据。</li>
      <li>类似读取事件， <code class="highlighter-rouge">FSDataOutputStream</code>封装一个<code class="highlighter-rouge">DFSoutPutStream</code>对象，该对象负责 datanode 与 namenoe之间的通信。</li>
    </ul>
  </li>
</ol>

<p>  在client写入时，<code class="highlighter-rouge">DFSOutputStream</code>将它分成一个个数据包，并写入内部队列，<strong>称为“数据队列” (data queue)</strong>。<code class="highlighter-rouge">DataStreamer </code>处理数据队列，它的责任是挑选出适合存储数据复本一组datanode，并据此来要求namenode分配新的数据块。</p>

<ol>
  <li>这<strong>一组datanode构成一个管线</strong>。
    <ul>
      <li>假设复本为3，所以管线中有3个节点。</li>
      <li><code class="highlighter-rouge">DataStreame</code>将数据包流式传输到管线中第1个datanode，该datanode存储数据包并将它发送到第2个datanode，同样第2个datanode存储该数据包并将它发送到第3个datanode。</li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">DFSOutputStream</code> 也维护着一个内部数据包队列来等待datanode的收到确定回执，<strong>称为“确认队列”(ack queue)</strong>。收到管道中所有的datanode确认信息后，该数据包才会被确认队列删除。</li>
</ol>

<p>如果任何datanode在数据写入期间发生故障，则执行以下操作（对写入数据client透明）。</p>

<ul>
  <li>
    <p>首先关闭管线，确认把队列中的所有数据包都添加回数据队列的最前端，以确保故障节点下游的datanode不会漏掉任何一个数据包。</p>
  </li>
  <li>为存储在另一正常datanode的当前数据块指定一个新的标识，并将该标识传送给namenode，以便故障datanode在恢复后可以删除存储部分数据块。</li>
  <li>从管线中删除故障datanode, 基于两个正常datanode构建一条新管线。余下数据写入管线中正常datanode。namenode注意到复本不足时，会在另一个节点上创建一个新的复本。</li>
</ul>

<p>同时不排除多个datanode同时发生故障的可能性。<strong>只要写入了dfs.namenode.replication.min的复本(默认为1)，写操作就会成功</strong>，并这个块可以在集群中异步复制，直到其达到复本数(dfs.replication的默认值 为3)。</p>

<ol>
  <li>client完成数据的写入后，对数据流调用close()方法。</li>
  <li>该操作将剩余的所有数据写入datanode管线， 并联系namenode告知其文件写入完成之前，等待确认。namenode已经知道文件由哪些块组成(因为DataStreamer请求分配数据块)，所以它在返回成功之前只需等待数据块进行最小量的复制。</li>
</ol>

<h4 id="复本存放问题">复本存放问题</h4>
<p>namenode 如何选择在哪个 datanode <strong>存放复本</strong>：</p>
<ol>
  <li>在运行客户端的节点上放第 1 个复本（如果客户端在集群外，就随机选择一个节点，系统会负载均衡）</li>
  <li>第2 个复本放在与第一个不同且随机另外选择的机架中节点上（离架）</li>
  <li>第 3 个复本放在与第2个复本同一个机架上， 且随机选择加一个节点。</li>
  <li>其他复本放在集群中随机节点上， 系统会尽量避免在同一个机架上放太多复本。</li>
</ol>

<p>一旦选定复本的放置位置，就根据网络拓扑结构创建一根管线。假设复本数为3。</p>

<p>​                                               <img src="https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/8A0c3G00EC.png" alt="mark" /></p>

<p><strong>参考:</strong></p>

<Hadoop权威指南第四版>
</Hadoop权威指南第四版>

    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="http://localhost:4000/assets/img/colorama-header.jpg" alt="">
      </div>
      <div class="author-name" rel="author">xlinboy</div>
      <div class="bio">
        <p>即将步入社会的年轻营</p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="https://github.com/xlinboy" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
      </ul>
      
    </section>

    <section class="post-footer-item comment">
      <div id="comment_container"></div>
    </section>

    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/hadoop/2018/12/Hadoop-%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F.html" class="read-next-link"></a>
        <section>
          <span>[Hadoop]安装方式</span>
          <p>下载</p>
        </section>
        
        <div class="filter"></div>
        <img src="../../../assets/img/hadoop-logo.jpg" alt="">
        
     </div>
      

      
      <div class="read-next-item">
        <a href="/hdfs/2018/12/HDFS-%E9%AB%98%E5%8F%AF%E7%94%A8.html" class="read-next-link"></a>
          <section>
            <span>[HDFS]高可用</span>
            <p>  它需要zookeeper的调度，首先配置zookeeper</p>
          </section>
          
          <div class="filter"></div>
          <img src="../../../assets/img/hadoop-logo.jpg" alt="">
          
      </div>
      
    </section>

  </section>

  <footer class="g-footer">
  <section>xlin的个人博客 ©
  
  
    2018
    -
  
  2019
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a> | <a href="https://github.com/kaeyleo/jekyll-theme-H2O">Theme H2O</a></section>
</footer>


  <script src="/assets/js/social-share.min.js"></script>
  <script>
    socialShare('.social-share', {
      sites: [
        
          'wechat'
          ,
          
        
          'weibo'
          ,
          
        
          'twitter'
          
        
      ],
      wechatQrcodeTitle: "分享到微信朋友圈",
      wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
  </script>

  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
