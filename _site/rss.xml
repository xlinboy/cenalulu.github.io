<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>xlin的个人博客</title>
    <description>记录编程的学习笔记</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sat, 12 Jan 2019 18:40:47 +0800</pubDate>
    <lastBuildDate>Sat, 12 Jan 2019 18:40:47 +0800</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>[Zookeeper]介绍</title>
        <description>&lt;h3 id=&quot;zookeeper-概念简介&quot;&gt;Zookeeper 概念简介&lt;/h3&gt;

&lt;p&gt;Zookeeper是一个分布式协调服务；就是为用户的分布式应用程序提供协调服务。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;为分布式程序提供服务&lt;/li&gt;
  &lt;li&gt;本身是一个分布式程序，只要半数以上存活,zk正常提供服务&lt;/li&gt;
  &lt;li&gt;zookeeper 涵盖：主从协调、统一名称服务…&lt;/li&gt;
  &lt;li&gt;zookeeper 底层只提供两个功能：
    &lt;ul&gt;
      &lt;li&gt;管理（存储，读取）用户程序提交的数据&lt;/li&gt;
      &lt;li&gt;并为用户程序提供数据节点监听服务&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Zookeeper默认只有leader和follower，没有observer。&lt;/p&gt;

&lt;p&gt;集群通过选举过程来选举来选定leader的机器， leader服务器为客户端提供读和写服务。&lt;/p&gt;

&lt;p&gt;Follower和Observer都能提供服务，不能提供写服务。Observer不参与Leader选举，也不参与写操作（过半写成功）策略。&lt;/p&gt;

&lt;h3 id=&quot;zookeeper工作机制&quot;&gt;zookeeper工作机制&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;基于观察者模式设计的分布式服务管理框架。&lt;/li&gt;
  &lt;li&gt;存储和管理大家都关心的数据（可自定义），然后接受观察者注册&lt;/li&gt;
  &lt;li&gt;一旦这些数据状态发生变化，zookeeper就将负责通知已经在zookeeper上注册的那些观察者(observer)做出相应的反应&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;zookeeper = 文件系统 + 通知机制&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;zookeeper-结构和特性&quot;&gt;zookeeper 结构和特性&lt;/h3&gt;

&lt;h4 id=&quot;zookeeper-特性&quot;&gt;zookeeper 特性&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;主从，一个leader, 多个follower组成的集群&lt;/li&gt;
  &lt;li&gt;全局数据一致：每个server保存一份相同的数据副本，client无论连接到哪个server，数据都是一致的&lt;/li&gt;
  &lt;li&gt;leader：分布式读写，更新请求转发&lt;/li&gt;
  &lt;li&gt;同一个client请求，FIFO&lt;/li&gt;
  &lt;li&gt;数据更新原子性。一次数据要么成功，要么失败。&lt;/li&gt;
  &lt;li&gt;实时性，一定时间范围内,client能读最新数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;zookeeper-数据结构&quot;&gt;zookeeper 数据结构&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;树型结构&lt;/li&gt;
  &lt;li&gt;每个节点在zookeeper中叫Zonde，并且有唯一标识&lt;/li&gt;
  &lt;li&gt;每个Zonde默认能够存储1MB数据，包含数据和子节点&lt;/li&gt;
  &lt;li&gt;客户端应用可以在节点上设置监听器&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;节点类型&quot;&gt;节点类型&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Zonde有两种类型
    &lt;ul&gt;
      &lt;li&gt;短暂 ephemeral, 断开链接即删除&lt;/li&gt;
      &lt;li&gt;持久 persistent, 断开链接不删除&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Zonde有四种形式的目录节点（默认是persistent）
    &lt;ul&gt;
      &lt;li&gt;PERSISTENT&lt;/li&gt;
      &lt;li&gt;PERSISTENT_SEQUENTIAL（持久序列/test0000000019 ）&lt;/li&gt;
      &lt;li&gt;EPHEMERAL&lt;/li&gt;
      &lt;li&gt;EPHEMERAL_SEQUENTIAL&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;创建znode时设置顺序标识，znode名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护&lt;/li&gt;
  &lt;li&gt;分布式系统中，顺序号可以被用于所有的事件，进行全局排序，这样客户端可以通过顺序号推断事件的顺序。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;状态信息&quot;&gt;状态信息&lt;/h3&gt;
&lt;p&gt;每个ZNode除了存储数据内容之外，还存储了ZNode本身的一些状态信息。用 get 命令可以同时获得某个ZNode的内容和状态信息。如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cZxid = 0xb00000002	事务id
ctime = Thu Nov 01 02:32:12 CST 2018	创建时间
mZxid = 0xb0000000e	最后更新的事物id
mtime = Thu Nov 01 02:39:36 CST 2018	最后修改的时间
pZxid = 0xb0000000f	最后更新的子节点事务id
cversion = 1	子节点修改次数
dataVersion = 1	数据变化号
aclVersion = 0	访问控制列表的变化号
ephemeralOwner = 0x0	临时节点的拥有者sessionid，若非临时节点，则为0
dataLength = 5	数据长度
numChildren = 1	子节点数量
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;watcher&quot;&gt;Watcher&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Watcher（事件监听器），是ZooKeeper中一个很重要的特性。ZooKeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去。该机制是ZooKeeper实现分布式协调服务的重要特性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;监听器原理-&quot;&gt;监听器原理： *&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/kDb2J2mA4i.png&quot; alt=&quot;mark&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;main()方法，启动client&lt;/li&gt;
  &lt;li&gt;在main线程中，创建client,这时会创建两个线程，一个负责网络连接通信(connect), 一个负责监听(listener)。&lt;/li&gt;
  &lt;li&gt;通过connect线程将注册的监听时间发送给zookeeper&lt;/li&gt;
  &lt;li&gt;在zookeeper的注册监听器列表中将注册的监听时间添加到列表&lt;/li&gt;
  &lt;li&gt;zookeeper监听到有数据或路径变化，就会将消息发送给listener线程&lt;/li&gt;
  &lt;li&gt;listener线程内部调用process()方法。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;写数据流程&quot;&gt;写数据流程&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/3KdEaimBf6.png&quot; alt=&quot;mark&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;client 连接到集群中的某一个节点&lt;/li&gt;
  &lt;li&gt;client 向server1发送写请求&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;若server1 不是leader，server转发给leader&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;leader会将写请求广播给各个server，leader会认识数据写成功了，并通知给server1&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;若半数以上的server都写成功了，leader会认为写操作成功，并通知server1&lt;/li&gt;
  &lt;li&gt;server1通知client，数据写成功了。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;zookeeper-的选举机制&quot;&gt;zookeeper 的选举机制&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;半数机制： 投票数达半数以上为leader&lt;/li&gt;
  &lt;li&gt;自私制 + 大数制&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;假设有5台机器&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;node1先启动，投票给自己，5台机器只有1票，作废&lt;/li&gt;
  &lt;li&gt;node2启动，node1投票给自己没有用，投票给node2，node2也投给自己，node2有两票&lt;/li&gt;
  &lt;li&gt;node3启动，node1投给myid最大的节点，node3，node2也投node3，node3也投自己，node3有3票，node3为leader&lt;/li&gt;
  &lt;li&gt;node4启动， node5启动&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sun, 16 Dec 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/zookeeper/2018/12/zookeeper-%E4%BB%8B%E7%BB%8D.html</link>
        <guid isPermaLink="true">http://localhost:4000/zookeeper/2018/12/zookeeper-%E4%BB%8B%E7%BB%8D.html</guid>
        
        <category>Zookeeper</category>
        
        
        <category>Zookeeper</category>
        
      </item>
    
      <item>
        <title>[Yarn]介绍</title>
        <description>&lt;h3 id=&quot;yarn基本思想&quot;&gt;yarn基本思想&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Apache Yarn (Yet Another Resource Negotiator)是hadoop的集群资源管理系统&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;yarn-运行机制&quot;&gt;yarn 运行机制&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/khjK9La260.png&quot; alt=&quot;mark&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了在yarn上运行一个应用&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;客户端联系Resource Manager 要求它运行一个application master进程&lt;/li&gt;
  &lt;li&gt;resource manager 找到一个能够在容量中启动application master 的node manager&lt;/li&gt;
  &lt;li&gt;application master 一旦运行起来后能做些什么都依赖应用本身
4.可能在所处的Container中简单地运行一个计算，并将结果返回客户端；或者是向Resource Manager 请求更多容量，以用于一个分布式运算。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;yarn本身不会为应用的各部分彼此间的通信提供任何手段&lt;/p&gt;

&lt;h4 id=&quot;resourcemanager-资源管理-技术总监&quot;&gt;ResourceManager 资源管理 技术总监&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;一个集群只有一个，全局资源管理器&lt;/li&gt;
  &lt;li&gt;负责启动客户端提交的Application&lt;/li&gt;
  &lt;li&gt;监控Node Manager，汇总上的的资源&lt;/li&gt;
  &lt;li&gt;根据请求分配资源&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;nodemanager-小组长&quot;&gt;NodeManager 小组长&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;每个从节点一个&lt;/li&gt;
  &lt;li&gt;监管自己所属节点的资源&lt;/li&gt;
  &lt;li&gt;监控资源使用情况并向Resource manager 汇报&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;让applicationmaster负责-任务调度-项目经理&quot;&gt;让ApplicationMaster负责 任务调度 项目经理&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;每个作业启动一个&lt;/li&gt;
  &lt;li&gt;根据作业切分任务tasks&lt;/li&gt;
  &lt;li&gt;向Resource Manager申请资源&lt;/li&gt;
  &lt;li&gt;与Node Manager协作，将分配申请到的资源给内部任务tasks&lt;/li&gt;
  &lt;li&gt;监控tasks运行情况， 重启失败任务&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;yarn计算资源抽象&quot;&gt;yarn计算资源抽象&lt;/h3&gt;

&lt;p&gt;在yarn中，计算资源被抽象为Container。&lt;/p&gt;

&lt;p&gt;每个Container描述&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;可以使用的Cpu资源和内存资源&lt;/li&gt;
  &lt;li&gt;执行命令&lt;/li&gt;
  &lt;li&gt;环境变量&lt;/li&gt;
  &lt;li&gt;外部资源&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如何获得运行各个任务的Container&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;由ApplicationMaster 向 ResourceManager申请&lt;/li&gt;
  &lt;li&gt;ApplicatinoMaster 本身也运行一个Container， 这个Container由ResourceManager向自身申请启动&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如何启动运行&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;向Container所属的NodeManager发起运行&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;和组件之间的心跳信号&quot;&gt;和组件之间的心跳信号&lt;/h3&gt;

&lt;h5 id=&quot;applicationmaster与resourcemanager心跳&quot;&gt;ApplicationMaster与ResourceManager心跳&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;AM =&amp;gt; RM
    &lt;ul&gt;
      &lt;li&gt;对Container的资源需求(cpu+memory)和优秀级&lt;/li&gt;
      &lt;li&gt;已用完等待回收的Container列表&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;RM =&amp;gt; AM
    &lt;ul&gt;
      &lt;li&gt;新申请到的Container&lt;/li&gt;
      &lt;li&gt;已完成的Container的状态&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;applicationmaster与nodemanager心跳&quot;&gt;ApplicationMaster与NodeManager心跳&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;AM =&amp;gt; NM
    &lt;ul&gt;
      &lt;li&gt;发起启动的Container请求&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;NM =&amp;gt; AM
    &lt;ul&gt;
      &lt;li&gt;汇报Container&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;nodemanager-与-resourcemanager心跳&quot;&gt;NodeManager 与 ResourceManager心跳&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;NM =&amp;gt; RM
    &lt;ul&gt;
      &lt;li&gt;Node Manager上所有的Container&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;RM =&amp;gt; NM
    &lt;ul&gt;
      &lt;li&gt;已删除和等待清理的Container列表&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;yarn调度器调度算法&quot;&gt;Yarn调度器&amp;amp;调度算法&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Yarn使用队列解决多租房中共享资源的问题。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;支持三种调度器：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;FIFO&lt;/li&gt;
  &lt;li&gt;Capacity Scheduler&lt;/li&gt;
  &lt;li&gt;Fair Scheduler&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;fifo调度器&quot;&gt;FIFO调度器&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;所有向集群提交的作业使用一个队列&lt;/li&gt;
  &lt;li&gt;根据提交作业的顺序运动&lt;/li&gt;
  &lt;li&gt;优点：
    &lt;ul&gt;
      &lt;li&gt;简单易懂&lt;/li&gt;
      &lt;li&gt;可以按照作业优先级调度&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;缺点：
    &lt;ul&gt;
      &lt;li&gt;资源利用率不高&lt;/li&gt;
      &lt;li&gt;不允许抢占&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;capacity-scheduler资源调度器&quot;&gt;Capacity Scheduler资源调度器&lt;/h4&gt;

&lt;p&gt;设计思想：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;资源按照比例分配给各个队列&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;特点&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;计算能力保证
    &lt;ul&gt;
      &lt;li&gt;以队列为单位划分资源，每个队列保证最低资源&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;灵活性
    &lt;ul&gt;
      &lt;li&gt;当某个队列空间时，其资源可以分配给其他的队列使用&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;支持优先级
    &lt;ul&gt;
      &lt;li&gt;单个队列内部使用FIFO， 支持作业优先级调度&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;多租房
    &lt;ul&gt;
      &lt;li&gt;综合考虑多种因素防止单个作业、用户、或者队列 独占资源&lt;/li&gt;
      &lt;li&gt;每个队列可以配置一定比例的最低资源配置和使用上限&lt;/li&gt;
      &lt;li&gt;每个队列有严格的访问限制 ，只能自己队列提交任务&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;capacity-scheduler资源分配算法&quot;&gt;Capacity Scheduler资源分配算法&lt;/h5&gt;

&lt;ol&gt;
  &lt;li&gt;选择队列
    &lt;ul&gt;
      &lt;li&gt;从跟队列开始，使用深度优先算法找出资源占用率最低的叶子节点&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;选择作业
    &lt;ul&gt;
      &lt;li&gt;默认按照作业优先级和提交时间顺序选择&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;选择Container
    &lt;ul&gt;
      &lt;li&gt;取该作业中最高优先级的Container，如果优先级相同会选择满足本地性的Container: Node Local &amp;gt; Rack Local &amp;gt; Different Rack&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;fair-scheduler-公平资源调度器&quot;&gt;Fair Scheduler 公平资源调度器&lt;/h4&gt;

&lt;p&gt;设置思想： 资源公平分配。&lt;/p&gt;

&lt;p&gt;具有与Capacity Scheduler 相似的特点。&lt;/p&gt;

&lt;p&gt;不同点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;核心策略不同
    &lt;ul&gt;
      &lt;li&gt;Capacity Scheduler 优先选择资源利用率最低的队列&lt;/li&gt;
      &lt;li&gt;Fair Scheduler考虑是公平的， 公平体现在作业对资源 分配&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;单独设置队列间资源分配方式
    &lt;ul&gt;
      &lt;li&gt;FAIR 默认 used memory/ min share&lt;/li&gt;
      &lt;li&gt;DRF 主资源公平调度&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;fair-scheduler---fair资源分配算法&quot;&gt;Fair Scheduler - FAIR资源分配算法&lt;/h5&gt;

&lt;p&gt;总体流程与Capacity Scheduler一致&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;选择队列&lt;/li&gt;
  &lt;li&gt;选择作业&lt;/li&gt;
  &lt;li&gt;选择Container&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;选择队列和作业使用公平排序算法&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;实际最小份额
    &lt;ul&gt;
      &lt;li&gt;mindshare = min (资源需求量， 配置minShare)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;是否饥饿
    &lt;ul&gt;
      &lt;li&gt;isNeedy = 资源使用量 &amp;lt; minShare&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;资源分配比
    &lt;ul&gt;
      &lt;li&gt;minShareRatio = 资源使用量/max(mindshare, 1)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;资源使用权重比
    &lt;ul&gt;
      &lt;li&gt;useToWeightRatio = 资源使用量/权重&lt;/li&gt;
      &lt;li&gt;权重 在配置文件中配置&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 16 Dec 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/yarn/2018/12/yarn.html</link>
        <guid isPermaLink="true">http://localhost:4000/yarn/2018/12/yarn.html</guid>
        
        <category>Yarn</category>
        
        
        <category>Yarn</category>
        
      </item>
    
      <item>
        <title>[Sqoop]操作</title>
        <description>&lt;h3 id=&quot;import&quot;&gt;Import&lt;/h3&gt;

&lt;h4 id=&quot;sqoop-to-hive&quot;&gt;Sqoop to hive&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sqoop import &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--connect&lt;/span&gt; jdbc:mysql://hadoop1:3306/test &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; root &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; 123456 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--table&lt;/span&gt; book_info &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--columns&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'book_id,book_name'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--where&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'book_id &amp;lt; 20'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--fields-terminated-by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\t'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--delete-target-dir&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--num-mappers&lt;/span&gt; 1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-import&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-database&lt;/span&gt; default &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-table&lt;/span&gt; book_info
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;还可以使用query&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sqoop import &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--connect&lt;/span&gt; jdbc:mysql://hadoop1:3306/test &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; root &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; 123456 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'select book_id,book_name from book_info where $CONDITIONS'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--target-dir&lt;/span&gt; /user/hive/book_info &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--fields-terminated-by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\t'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--delete-target-dir&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--num-mappers&lt;/span&gt; 1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-import&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-database&lt;/span&gt; default &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-table&lt;/span&gt; book_info
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;如果使用query， 就不需要指定–column, –table, –where&lt;/li&gt;
  &lt;li&gt;conditions 相当于1=1
    &lt;h4 id=&quot;sqoop-增量导入&quot;&gt;Sqoop 增量导入&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;append-自增id&quot;&gt;append 自增id&lt;/h5&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sqoop import &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--connect&lt;/span&gt; jdbc:mysql://hadoop1:3306/test &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; root &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; 123456 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--table&lt;/span&gt; book_info &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--columns&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'book_id,book_name'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--fields-terminated-by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\t'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--num-mappers&lt;/span&gt; 1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-import&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-database&lt;/span&gt; default &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-table&lt;/span&gt; book_info &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--incremental&lt;/span&gt; append &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--check-column&lt;/span&gt; book_id &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--last-value&lt;/span&gt; 20 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;lastmodified-日期&quot;&gt;lastmodified 日期&lt;/h4&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sqoop import &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--connect&lt;/span&gt; jdbc:mysql://hadoop1:3306/test &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; root &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; 123456 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--table&lt;/span&gt; book_info &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--columns&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'book_id,publish_date'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--fields-terminated-by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\t'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--num-mappers&lt;/span&gt; 1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-import&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-database&lt;/span&gt; default &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-table&lt;/span&gt; book_info &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--incremental&lt;/span&gt; lastmodified &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--check-column&lt;/span&gt; publish_date &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--last-value&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'2018-07-10 19:53:40'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;export&quot;&gt;export&lt;/h3&gt;

&lt;h4 id=&quot;导出到mysql&quot;&gt;导出到mysql&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sqoop &lt;span class=&quot;nb&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--connect&lt;/span&gt;  jdbc:mysql://hadoop1:3306/test &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--driver&lt;/span&gt; com.mysql.jdbc.Driver &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; root &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; 123456 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--table&lt;/span&gt; recruitment &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--fields-terminated-by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\001'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--export-dir&lt;/span&gt; /user/hive/warehouse/work.db/job_tmp &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;更新mysql字段&quot;&gt;更新mysql字段&lt;/h4&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sqoop &lt;span class=&quot;nb&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--connect&lt;/span&gt; jdbc:mysql://hadoop1:3306/test &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; root &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; 123456 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--driver&lt;/span&gt; com.mysql.jdbc.Driver &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--columns&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'id,salary'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--table&lt;/span&gt; work_info &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--fields-terminated-by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\t'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--export-dir&lt;/span&gt; /user/hive/warehouse/work.db/job_info_textfile &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--update-key&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'id'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Sun, 16 Dec 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/sqoop/2018/12/Sqoop-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C.html</link>
        <guid isPermaLink="true">http://localhost:4000/sqoop/2018/12/Sqoop-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C.html</guid>
        
        <category>Sqoop</category>
        
        
        <category>Sqoop</category>
        
      </item>
    
      <item>
        <title>[Sqoop]基础知识</title>
        <description>&lt;h3 id=&quot;1-问题&quot;&gt;1. 问题&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;假设：目前正式生产环境的数据出现了错误或者是偏差（2000w）修正这些错误？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;解决：利用&lt;strong&gt;sqoop（数据修正）&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-sqoop是什么&quot;&gt;2. sqoop是什么&lt;/h3&gt;
&lt;p&gt;全称：SQL TO HADOOP&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;sqoop 是一个hadoop与关系弄数据库之间相互数据传输的工具。sqoop可以将数据从关系型数据库, (例如mysql或oracle或大型机) 导入到hdfs，转换成MapReduce数据，然后将数据导回到关系型数据库。&lt;/p&gt;

  &lt;p&gt;sqoop的import依赖数据库的描述约束。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;sqoop本质是mapreduce，但是仅存在Map task。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;sqoop 将sql转化成.java文件打成jar包执行mapreduce&lt;/p&gt;

&lt;h4 id=&quot;sqoop-执行流程&quot;&gt;sqoop 执行流程&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/sqoop%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;准备数据集 (preparing resultset)&lt;/li&gt;
  &lt;li&gt;生成mapreduce,.java文件 (codgen)&lt;/li&gt;
  &lt;li&gt;打成jar包, (compile jar)
    &lt;ul&gt;
      &lt;li&gt;执行查询拉取数据&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;到yarn上执行map task (mapreduce on yarn)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;3-环境依赖&quot;&gt;3. 环境依赖&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;hadoop&lt;/li&gt;
  &lt;li&gt;hive&lt;/li&gt;
  &lt;li&gt;hbase&lt;/li&gt;
  &lt;li&gt;zookeeper&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;4-基础用法&quot;&gt;4. 基础用法&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;对于数据库，sqoop将逐行导入hdfs。&lt;/li&gt;
  &lt;li&gt;对于大型的数据集，sqoop从不同的大型数据集读记录到hdfs。&lt;/li&gt;
  &lt;li&gt;导入的进程是并行的&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;通用链接参数&quot;&gt;通用链接参数&lt;/h4&gt;
&lt;p&gt;sqoop 连接数据库三要素：&lt;/p&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;--connect&lt;/span&gt; &amp;lt;jdbc-uri&amp;gt; 指定要连接的数据库
&lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; &amp;lt;username&amp;gt; 访问数据库的用户名
&lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; &amp;lt;password&amp;gt;  访问数据库的密码
&lt;span class=&quot;nt&quot;&gt;--table&lt;/span&gt; TEST			设置要访问的表
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;5-import&quot;&gt;5. Import&lt;/h3&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sqoop import &lt;span class=&quot;nt&quot;&gt;--connect&lt;/span&gt; jdbc:mysql://hadoop1/test &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; root &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; 123456 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--table&lt;/span&gt; book_info
&lt;span class=&quot;nt&quot;&gt;--columns&lt;/span&gt; book_name, book_type &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--fields-terminated-by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\t'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--delete-target-dir&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--num-mappers&lt;/span&gt; 1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;num-mappers：指明map task的数目&lt;/li&gt;
  &lt;li&gt;direct，是msql中提高查询 效率的工具 mysqldump, &lt;code class=&quot;highlighter-rouge&quot;&gt;select * from xx&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;columns 指定列&lt;/li&gt;
  &lt;li&gt;fields-terminated-by 指定分隔符&lt;/li&gt;
  &lt;li&gt;delete-target-dir  如果文件存在则删除, 不能和增量导入一起使用&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;注意：&lt;strong&gt;如果要使用direct参数，需要将mysqldump文件添加每台datanode的/usr/bin下也就是说mysqldump操作是由集群中的datanode节点来执行。&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;指定文件来执行sqoop&quot;&gt;指定文件来执行sqoop&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sqoop --options-file /users/homer/work/import.txt --table TEST  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;options-file：指定文件读取目录。&lt;/li&gt;
  &lt;li&gt;fields-terminated-by：指定内容行字段的分隔符，默认以逗号分割。&lt;/li&gt;
  &lt;li&gt;delete-target-dir：如果导入的hdfsh目录存在，则删除。&lt;/li&gt;
  &lt;li&gt;target-dir：指定import,导入的hdfs路径。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Import&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Hive&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--hive-import&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--hive-database &amp;lt;database-name&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--hive-table &amp;lt;table-name&amp;gt;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;hive&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;的日志，除了在&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;下，还可以有&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;下可以看到&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;java.lang.ClassNotFoundException&lt;/strong&gt;：找不到对应jar包&lt;/p&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;需要将对应的依赖包导入到 sqoop/lib包下

hive/lib/jdo-&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;-.jar 
        hive-&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;-.jar
        antlr-&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;-.jar
		calcite-&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;-.jar
		datanucleus-&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;-.jar
		
拷贝hive/conf/hive-site.xml到sqoop/conf下
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Sun, 16 Dec 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/sqoop/2018/12/Sqoop-%E5%9F%BA%E7%A1%80.html</link>
        <guid isPermaLink="true">http://localhost:4000/sqoop/2018/12/Sqoop-%E5%9F%BA%E7%A1%80.html</guid>
        
        <category>Sqoop</category>
        
        
        <category>Sqoop</category>
        
      </item>
    
      <item>
        <title>[Sqoop]操作实战</title>
        <description>&lt;h2 id=&quot;需求&quot;&gt;需求&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;现在发现职业分析数据库中，各大城市中工作1-3的大数据人员的薪资出现偏差,偏差值为2000, 修改该偏差值，并更新RBDMS中。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;创建textfile-hive表&quot;&gt;创建textfile hive表&lt;/h3&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_info_textfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;将误差数据导入到hive中&quot;&gt;将误差数据导入到hive中&lt;/h3&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sqoop import &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--connect&lt;/span&gt; jdbc:mysql://hadoop1:3306/test &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; root &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; 123456 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--table&lt;/span&gt; recruitment &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--columns&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'id, salary'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--where&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;' work_experience&amp;gt;=1 and work_experience&amp;lt;=3'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--delete-target-dir&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--fields-terminated-by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\t'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-import&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-database&lt;/span&gt; work &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--hive-table&lt;/span&gt; job_info_textfile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;创建orc-更新acid表&quot;&gt;创建orc 更新ACID表&lt;/h3&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_info_orc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;float&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;clustered&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buckets&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;stored&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ORC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tblproperties&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'transactional'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'true'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;将误差数据导入orc格式的表中&quot;&gt;将误差数据导入orc格式的表中&lt;/h3&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_info_orc&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_info_textfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;将误差修正&quot;&gt;将误差修正&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update work.job_info_orc SET salary = salary-2000;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;将修正好的数据导致textfile中&quot;&gt;将修正好的数据，导致textfile中&lt;/h3&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_info_textfile&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;salary&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;work&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_info_orc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;将mysql中的误差数据更新&quot;&gt;将mysql中的误差数据更新&lt;/h3&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sqoop &lt;span class=&quot;nb&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--connect&lt;/span&gt; jdbc:mysql://hadoop1:3306/test &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; root &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--password&lt;/span&gt; 123456 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--driver&lt;/span&gt; com.mysql.jdbc.Driver &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--columns&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'id,salary'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--num-mappers&lt;/span&gt; 5&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--table&lt;/span&gt; recruitment &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--fields-terminated-by&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'\t'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--export-dir&lt;/span&gt; /user/hive/warehouse/work.db/job_info_textfile &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--update-key&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'id'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Sun, 16 Dec 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/sqoop/2018/12/Sqoop-%E4%BF%AE%E6%94%B9%E8%AF%AF%E5%B7%AE%E6%95%B0%E6%8D%AE.html</link>
        <guid isPermaLink="true">http://localhost:4000/sqoop/2018/12/Sqoop-%E4%BF%AE%E6%94%B9%E8%AF%AF%E5%B7%AE%E6%95%B0%E6%8D%AE.html</guid>
        
        <category>Sqoop</category>
        
        
        <category>Sqoop</category>
        
      </item>
    
      <item>
        <title>[Secondary NameNode]详解</title>
        <description>&lt;h2 id=&quot;namenode&quot;&gt;NameNode&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;主要用来保存HDFS元数据信息，比如命名空间信息，块信息等。当它运行的时候，这些信息是存在内存中的。但是这些信息也可以持久化到磁盘上。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/6b8FC7bb9f.png&quot; alt=&quot;mark&quot; /&gt;&lt;/p&gt;

&lt;p&gt;fsimage: 它是在NameNode启动时对整个文件系统的快照&lt;/p&gt;

&lt;p&gt;edits log: 它是在NameNode启动后，对文件系统的改动序列&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;只有在NameNode重启时，edits log才会合并到fsimage文件中，从而得到一个文件系统的最新快照。但是在生产环境集群中的NameNode是很少重启的， &lt;strong&gt;这意味者当NameNode运行来很长时间后，edits文件会变的很大。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在这种情况下就会出现下面这些问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;edits log文件会变的很大，怎么去管理这个文件是一个挑战。&lt;/li&gt;
  &lt;li&gt;NameNode的重启会花费很长时间，因为有很多改动[在edits log中]要合并到fsimage文件上。&lt;/li&gt;
  &lt;li&gt;如果NameNode挂掉了，那我们就丢失了很多改动因为此时的fsimage文件非常旧。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;secondary-namenode&quot;&gt;Secondary NameNode&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;主要作用：帮我们减少edits log文件的大小和得到一个最新的fsimage文件，从减少namenode的压力。&lt;/p&gt;

  &lt;p&gt;它的职责是，合并NameNode的edits  log到fsimage文件中&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/DF19igj73D.png&quot; alt=&quot;mark&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;客户端向namenode发出更新元数据的请求&lt;/li&gt;
  &lt;li&gt;snn 向nn请求checkpoint（合并数据）&lt;/li&gt;
  &lt;li&gt;此时namenode会滚动当前在操作的日志文件edits.inprogress。&lt;/li&gt;
  &lt;li&gt;snn会将edits文件(多个滚动的文件)和镜像文件fsimage下载&lt;/li&gt;
  &lt;li&gt;根据操作日志文件根据一些算法计算出元数据从而来和镜像文件进行合并存到内存中。&lt;/li&gt;
  &lt;li&gt;将合并后的元数据dump成新的image文件，持久化到硬盘(fsimage.chkpoint)&lt;/li&gt;
  &lt;li&gt;上传新的fsimage到NameNode。&lt;/li&gt;
  &lt;li&gt;NameNode把旧的fsimage用新的覆盖掉。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;日志的滚动&quot;&gt;日志的滚动：&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;日志文件是一个正在写的edits.inprogress,多个滚动的ecits.000001..。checkpoint时，将正在写的滚动。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;snn的特点&quot;&gt;SNN的特点：&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;Secondary NameNode所做的是在文件系统这设置一个Checkpoint来&lt;strong&gt;帮助NameNode更好的工作&lt;/strong&gt;;它不是取代NameNode，也不是NameNode的备份。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Secondary NameNode的检查进程启动，由两个参数配置:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;fs.checkpoint.period，指定连续两次检查点的最大时间间隔， 默认值是1小时。&lt;/li&gt;
  &lt;li&gt;fs.checkpoint.size定义了edits日志文件的最大值，一旦超过这个值会导致强制执行检查点（即使没到检查点的最大时间间隔）。默认值是64MB。&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;NameNode会从fs.checkpoint.dir目录读取检查点，并把它保存在dfs.name.dir目录下。
    &lt;ul&gt;
      &lt;li&gt;如果dfs.name.dir目录下有合法的镜像文件，NameNode会启动失败。 NameNode会检查fs.checkpoint.dir目录下镜像文件的一致性，但是不会去改动它。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果NameNode上除了最新的检查点以外，所有的其他的历史镜像和edits文件都丢失了， NameNode可以引入这个最新的检查点。以下操作可以实现这个功能：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;在配置参数dfs.name.dir指定的位置建立一个空文件夹；&lt;/li&gt;
  &lt;li&gt;把检查点目录的位置赋值给配置参数fs.checkpoint.dir；&lt;/li&gt;
  &lt;li&gt;启动NameNode，并加上-importCheckpoint。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;NameNode硬盘坏了，数据能恢复吗？如果能，能够全部恢复吗？&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;能, 把Secondary NameNode的元数据拷贝给namenode&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;不能, 可能会丢失最后一次操作30min内(默认时间)或不超过64M大小数据的所有操作&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;NameNode宕机了，有Sercondary NameNode存在，所以hdfs还是只可以用的吗？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不可以，Secondary NameNode只是协助进行元数据合并，不对外提供服务，所以hdfs会瘫痪。
热备：你坏了，我立马顶上。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有Sercondary NameNode 和NameNode我们配置时需要注意什么？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;NameNode, Secondary NameNode不能配置在同一个节点上&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;hdfs的工作目录，至少配置两个，会同时向两个目录写东西，内容完全一样。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 16 Dec 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/hadoop/2018/12/Secondary-NameNode-(SNN).html</link>
        <guid isPermaLink="true">http://localhost:4000/hadoop/2018/12/Secondary-NameNode-(SNN).html</guid>
        
        <category>Hadoop</category>
        
        
        <category>Hadoop</category>
        
      </item>
    
      <item>
        <title>[Mapreduce]执行流程</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;MapReduce是一个分布式运算程序的编程框架。其核心功能是：将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程式。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;mapreduce框架结构以及核心机制&quot;&gt;MapReduce框架结构以及核心机制&lt;/h3&gt;
&lt;p&gt;一个完整的mapreduce程序在分布式运行时有三类实例进程：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;MRAppMaster：负责整个程序的过程调度及状态协调&lt;/li&gt;
  &lt;li&gt;MapTask：负责map阶段整个数据处理流程&lt;/li&gt;
  &lt;li&gt;ReduceTask：负责reduce阶段的整个数据处理流程&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;流程图&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/dbfjHdHKiG.png&quot; alt=&quot;mark&quot; /&gt;&lt;/p&gt;
&lt;h4 id=&quot;流程分析&quot;&gt;流程分析&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;一个mr程序启动的时候，最先启动的是MRAppMaster，MRAppMaster启动后根据本次job的描述信息，计算出需要的maptask实例数量，然后向集群申请机器启动相应数量的maptask进程&lt;/li&gt;
  &lt;li&gt;maptask进程启动之后，根据给定的数据切片范围进行数据处理，主体流程为：
    &lt;ol&gt;
      &lt;li&gt;利用客户指定的inputformat来获取RecordReader读取数据，形成输入&amp;lt;K,V&amp;gt;对&lt;/li&gt;
      &lt;li&gt;将输入KV对传递给客户定义的map()方法，做逻辑运算，并将map()方法输出的KV对收集到缓存&lt;/li&gt;
      &lt;li&gt;将缓存中的KV对按照K分区排序后不断溢写到磁盘文件&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;MRAppMaster监控到所有maptask进程任务完成之后，会根据客户指定的参数启动相应数量的reducetask进程，并告知reducetask进程要处理的数据范围（数据分区）&lt;/li&gt;
  &lt;li&gt;Reducetask进程启动之后，根据MRAppMaster告知的待处理数据所在位置，从若干台maptask运行所在机器上获取到若干个maptask输出结果文件，并在本地进行重新归并排序，然后按照相同key的KV为一个组，调用客户定义的reduce()方法进行逻辑运算，并收集运算输出的结果KV，然后调用客户指定的outputformat将结果数据输出到外部存储&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;maptask并行度的决定机制&quot;&gt;MapTask并行度的决定机制&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;一个job的map阶段并行度由客户端在提交job时决定&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;客户端对map阶段并行度的规划的基本逻辑为:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将待处理数据执行逻辑切片（即按照一个特定切片大小，将待处理数据划分成逻辑上的多个split），然后&lt;strong&gt;每一个split分配一个mapTask并行实例处理&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;逻辑切片规划描述文件，由FileInputFormat实现类的getSplits()方法完成：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/3Fb2Fm7Fb3.png&quot; alt=&quot;mark&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;fileinputformat切片机制&quot;&gt;FileInputFormat切片机制&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;切片定义在InputFormat类中的getSpilt()方法&lt;/li&gt;
  &lt;li&gt;FileInputFormat中默认的切片机制：
    &lt;ul&gt;
      &lt;li&gt;简单地按照文件的内容长度进行切片&lt;/li&gt;
      &lt;li&gt;切片大小，默认等于block大小&lt;/li&gt;
      &lt;li&gt;切片时不考虑数据集整体，而是逐个针对每一个文件单独切片&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;比如有两个待处理文件&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;file1.txt    320M
file2.txt    10M
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;经过FileInputFormat的切片机制运算后，形成的切片信息如下：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;file1.txt.split1--  0~128
file1.txt.split2--  128~256
file1.txt.split3--  256~320
file2.txt.split1--  0~10M
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;FileInputFormat中切片的大小参数配置&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;计算切片大小逻辑：Math.max(minSize, Math.min(maxSize, blockSize))&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;minsize：默认值：1  
  	配置参数： mapreduce.input.fileinputformat.split.minsize 
maxsize：默认值：Long.MAXValue  
    配置参数：mapreduce.input.fileinputformat.split.maxsize
 
blocksize
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;默认情况下，切片大小=blocksize&lt;/strong&gt;。如果最后一块大小小于切片大小的1.1倍，会放在同一个块&lt;/p&gt;

&lt;h3 id=&quot;mapreduce中的combiner&quot;&gt;MapReduce中的Combiner&lt;/h3&gt;
&lt;p&gt;Combiner的使用要非常谨慎&lt;/p&gt;

&lt;p&gt;因为combiner在mapreduce过程中可能调用也肯能不调用，可能调一次也可能调多次&lt;/p&gt;

&lt;p&gt;所以：combiner使用的原则是：有或没有都不能影响业务逻辑&lt;/p&gt;

&lt;h4 id=&quot;combiner简介&quot;&gt;Combiner简介&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;combiner是MR程序中Mapper和Reducer之外的一种组件&lt;/li&gt;
  &lt;li&gt;combiner组件的父类就是Reducer&lt;/li&gt;
  &lt;li&gt;combiner和reducer的区别在于运行的位置：
    &lt;ul&gt;
      &lt;li&gt;Combiner是在每一个maptask所在的节点运行;&lt;/li&gt;
      &lt;li&gt;Combiner是在每一个maptask所在的节点运行;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;combiner的意义就是对每一个maptask的输出进行局部汇总，以减小网络传输量&lt;/li&gt;
  &lt;li&gt;combiner能够应用的前提是不能影响最终的业务逻辑&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;combiner的输出kv应该跟reducer的输入kv类型要对应起来&lt;/p&gt;

&lt;h4 id=&quot;具体实现步骤&quot;&gt;具体实现步骤&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;自定义一个combiner继承Reducer，重写reduce方法&lt;/li&gt;
  &lt;li&gt;在job中设置：  job.setCombinerClass(CustomCombiner.class)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;mapreduce的shuffle机制&quot;&gt;MapReduce的shuffle机制&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;mapreduce中，map阶段处理的数据如何传递给reduce阶段，是mapreduce框架中最关键的一个流程，这个流程就叫shuffle。&lt;/li&gt;
  &lt;li&gt;shuffle：洗牌、发版、混洗–核心机制：数据分区，排序，缓存。&lt;/li&gt;
  &lt;li&gt;具体来说：就是将maptask输出的处理结果数据，分发给reducetask，并在分发的过程中，对数据按key进行了分区和排序。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;详细过程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/6C2kDE0946.png&quot; alt=&quot;mark&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;maptask收集我们的map()方法输出的&amp;lt;k,v&amp;gt;对，放到缓形缓冲区（数组）。&lt;/li&gt;
  &lt;li&gt;从内存缓冲区不断溢出本地磁盘（环形缓冲区需要进行排序，以不会写满在溢出），可能会溢出多个文件。&lt;/li&gt;
  &lt;li&gt;多个溢出文件会被合并成大的溢出文件。&lt;/li&gt;
  &lt;li&gt;在溢出过程中，及合并的过程中，都要调用partitoner进行分组和针对key进行排序。&lt;/li&gt;
  &lt;li&gt;reducetask根据自己的分区号，去各个maptask机器上取相应的结果分区数。&lt;/li&gt;
  &lt;li&gt;reducetask会取到同一个分区的来自不同maptask的结果文件，reducetask会将这些文件再进行合并（归并排序）。&lt;/li&gt;
  &lt;li&gt;合并成大文件后，shuffle的过程也就结束了，后面进入reducetask的逻辑运算过程（从文件中取出一个一个的键值对group，调用用户自定义的reduce()方法）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Shuffle中的缓冲区大小会影响到mapreduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。  &lt;br /&gt;
缓冲区的大小可以通过参数调整,  参数：io.sort.mb  默认100M&lt;/p&gt;

&lt;h3 id=&quot;mapreduce中有序列化&quot;&gt;MapReduce中有序列化&lt;/h3&gt;

&lt;p&gt;Java的序列化太冗余不好，hadoope有一套自己的序列化机制（Writable）&lt;/p&gt;

&lt;h4 id=&quot;自定义序列化接口&quot;&gt;自定义序列化接口&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;不需要比较只需要继承Writable即可&lt;/li&gt;
  &lt;li&gt;如果需要将自定义的bean放在key中传输，则还需要实现comparable接口，因为&lt;strong&gt;mapreduce框中的shuffle过程一定会对key进行排序&lt;/strong&gt;,此时，自定义的bean实现的接口应该是：
&lt;code class=&quot;highlighter-rouge&quot;&gt;public  class  FlowBean  implements  WritableComparable&amp;lt;FlowBean&amp;gt; &lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
	 * 反序列化的方法，反序列化时，从流中读取到的各个字段的顺序应该与序列化时写出去的顺序保持一致
	 */
	@Override
	public void readFields(DataInput in) throws IOException {
		upflow = in.readLong();
		dflow = in.readLong();
		sumflow = in.readLong();
	}
	/**
	 * 序列化的方法
	 */
	@Override
	public void write(DataOutput out) throws IOException {
		out.writeLong(upflow);
		out.writeLong(dflow);
		//可以考虑不序列化总流量，因为总流量是可以通过上行流量和下行流量计算出来的
		out.writeLong(sumflow);

	}
	
	@Override
	public int compareTo(FlowBean o) {
		
		//实现按照sumflow的大小倒序排序
		return sumflow&amp;gt;o.getSumflow()?-1:1;
	}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;mapreduce中的分区partitioner&quot;&gt;Mapreduce中的分区Partitioner&lt;/h3&gt;

&lt;p&gt;Mapreduce中会将map输出的kv对，按照相同key分组，然后分发给不同的reducetask&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;默认的分发规则为：根据key的hashcode%reducetask数来分发&lt;/strong&gt;。 
自定义Partitioner类需要继承抽象类CustomPartitioner 
然后在job对象中，设置自定义partitioner： job.setPartitionerClass(CustomPartitioner.class)&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Dec 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/hadoop/2018/12/MapReduce-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.html</link>
        <guid isPermaLink="true">http://localhost:4000/hadoop/2018/12/MapReduce-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.html</guid>
        
        <category>Hadoop</category>
        
        
        <category>Hadoop</category>
        
      </item>
    
      <item>
        <title>[HBase]操作</title>
        <description>&lt;h3 id=&quot;1-shell-创建表的多种形式&quot;&gt;1. shell 创建表的多种形式&lt;/h3&gt;

&lt;p&gt;注意命名空间、多个列簇及属性&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;Create&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ns1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;qualifier&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ns1:t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VERSIONS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;Create&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;qualifier&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f2'&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f3'&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;The&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;above&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shorthand&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;would&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;be&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;following&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f3'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VERSIONS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TTL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2592000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BLOCKCACHE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CONFIGURATION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'hbase.hstore.blockingStoreFiles'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'10'&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;2-预分区&quot;&gt;2. 预分区&lt;/h3&gt;
&lt;p&gt;table 逻辑上的分区，以行的形式存储&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;region 
startkey, endkey
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;默认情况下，创建表hbase表会自动为表分区&lt;/li&gt;
  &lt;li&gt;一般情况下，创建好表之后，会导入大量数据
    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bulk&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;load&lt;/span&gt;
    
  &lt;span class=&quot;n&quot;&gt;region&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;managed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regionserver&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;split&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;two&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;region&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;regionserver&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;负载大&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;所以，一般会在创建表的时候就创建多个region，依据表的rowkey进行设计，结合业务&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;如何预先创建多个region？ &lt;strong&gt;hbase表的预分区&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;region划分依赖rowkey，预估rowkey的划分准则&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;region划分依赖rowkey，预估rowkey的划分准则&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ns1:t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SPLITS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'10'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'20'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'30'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'40'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'h_work'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'info'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SPLITS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'001'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'002'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'003'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'004'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'007'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'015'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'050'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'100'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'150'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'200'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'250'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'300'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SPLITS_FILE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'splits.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OWNER&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'johndoe'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VERSIONS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;METADATA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'mykey'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'myvalue'&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optionally&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pre&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NUMREGIONS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SPLITALGO&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;HexStringSplit&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;UniformSplit&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NUMREGIONS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SPLITALGO&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'HexStringSplit'&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NUMREGIONS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SPLITALGO&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'HexStringSplit'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;REGION_REPLICATION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CONFIGURATION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'hbase.hregion.scan.loadColumnFamiliesOnDemand'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'true'&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'t1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'f1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DFS_REPLICATION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;如：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;create ‘logs’,’info’,SPLITS =&amp;gt; [‘20181010’,’20181020’,’20181030’]&lt;/li&gt;
  &lt;li&gt;指定分隔文件
 create ‘logs’,’info’,SPLITS =&amp;gt; ‘opt/datas/logs_split.txt’&lt;/li&gt;
  &lt;li&gt;指定多少分区，十六进制字符串分割
 create ‘t1’, ‘f1’, {NUMREGIONS =&amp;gt; 3, SPLITALGO =&amp;gt; ‘HexStringSplit’}&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;表属性&quot;&gt;表属性&lt;/h3&gt;
&lt;p&gt;查看一张表的属性，describe ‘user’&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COLUMN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FAMILIES&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DESCRIPTION&lt;/span&gt;                                                     
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'info'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;BLOOMFILTER&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ROW'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;err&quot;&gt;布隆过滤器&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;VERSIONS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;IN_MEMORY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'false'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;KEEP_DELETED_CELLS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'FALSE'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;DATA_BLOCK_ENCODING&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'NONE'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 	
&lt;span class=&quot;n&quot;&gt;TTL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'FOREVER'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;COMPRESSION&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'NONE'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 	&lt;span class=&quot;err&quot;&gt;压缩属性&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;checknative&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;查看当前&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;支持哪些压缩&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;MIN_VERSIONS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'0'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;BLOCKCACHE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'true'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;BLOCKSIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'65536'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;REPLICATION_SCOPE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'0'&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;1-压缩属性&quot;&gt;1. 压缩属性&lt;/h4&gt;
&lt;p&gt;配置hbase的snappyd压缩&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;配置hadoop 的压缩配置&lt;/li&gt;
  &lt;li&gt;配置hbase
    &lt;ul&gt;
      &lt;li&gt;hadoop-snappy-0.0.1-SNAPSHOT.jar放到hbase的lib下&lt;/li&gt;
      &lt;li&gt;需要将本地的库native内容放到hbase的lib下的native目录下&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;创建软连接即可&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ln&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;native&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HBASE_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;native&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;amd64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;然后创建表的时候，可以指定d压缩属性。&lt;/p&gt;

&lt;p&gt;需要强制告诉regionserver，配置hbase.regionserver.codecs的value为snappy，且重启regionserver生效&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;但是如果原表里面已经有了很多数据，那么压缩是不会生效的&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;2-regionserver的内存&quot;&gt;2. regionserver的内存&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;memstore 40%&lt;/li&gt;
  &lt;li&gt;blockcache 40%，块缓存每个regionserver只有一个blockcache&lt;/li&gt;
  &lt;li&gt;other&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;客户端读取数据会从三个地方读取数据，按顺序读取&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;memstore&lt;/li&gt;
  &lt;li&gt;blockcache&lt;/li&gt;
  &lt;li&gt;hfile
然后进行merge合并，返回数据集。&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;cache的等级&quot;&gt;cache的等级&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;immemory:0.25, 即缓存数据放在不轻易删除的内存中，如meta元数据信息。&lt;code class=&quot;highlighter-rouge&quot;&gt;describe 'inmemory'&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;multi:0.50, 即比较重要的数据&lt;/li&gt;
  &lt;li&gt;single:0.25, 即可以缓存也可以不缓存的信息，最少使用的会加入到淘汰算法&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;表的compaction&quot;&gt;表的compaction&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;minor合并:多个小文件合并成多个大文件，即多路归并，受磁盘IO影响。&lt;/li&gt;
  &lt;li&gt;major合并，将一个region中的一列簇的所有hfile重写为一个新的hfile。扫描所有的键值对，顺序重写全部的数据。重写数据过程，略过做了删除标记的数据，以及超出版本号限制的数据。&lt;/li&gt;
  &lt;li&gt;重量级合并：阻塞所有的region的请求，有时间限制 ，直到合并完毕。小心死循环&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hbasehiveimpala&quot;&gt;HBase+Hive/impala&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;https://cwiki.apache.org/confluence/display/hive/hbaseintegration&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;数据存储在HBase&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;表的描述信息存储在hive中
 hive从0.9.0版本才开始支持与HBase集成&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;集成方式&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;管理表&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;  创建hive表的时候，指定数据存储在hbase表中
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;外部表&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;现在已经存在了一个hbase表，需要对表中的数据进行分析&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;本质&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;hive就是hbase的客户端，需要jar包以及配置&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;需要将hbase的依赖jar拷贝到hive/lib下&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;包括&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;common&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;protocol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;htrace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;zookeeper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;guave&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;版本要一致，以&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hbase&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;版本为准&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;在hive-site.xml文件中，添加zookeeper参数&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hbase.zookeeper.quorum
hadoop1,hadoop2,hadoop3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;创建一张hive管理表
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  CREATE TABLE hbase_table_1(key int, value string) 
  STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
  WITH SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; = &quot;:key,cf1:val&quot;)
  TBLPROPERTIES (&quot;hbase.table.name&quot; = &quot;xyz&quot;, &quot;hbase.mapred.output.outputtable&quot; = &quot;xyz&quot;);
       
  建表之后，查看表的描述信息
  hive&amp;gt; desc formatted hbase_table_1;
  hbase&amp;gt; describe 'xyz'
       
  使用hive语句导入数据
  hbase&amp;gt; scan 'xyz'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;外部表
   即把已有的hbase表映射到hive的表&lt;/p&gt;

    &lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   &lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXTERNAL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hbase_table_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
   &lt;span class=&quot;n&quot;&gt;STORED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'org.apache.hadoop.hive.hbase.HBaseStorageHandler'&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SERDEPROPERTIES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;hbase.columns.mapping&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;cf1:val&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;TBLPROPERTIES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;&quot;hbase.table.name&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;some_existing_table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;hbase.mapred.output.outputtable&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;&quot;some_existing_table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;应用场景
    &lt;ul&gt;
      &lt;li&gt;有时候的数据迁移也是用这种方法&lt;/li&gt;
      &lt;li&gt;如日志文件保存到hbase表&lt;/li&gt;
      &lt;li&gt;导入hive表，使用列分割全表数据&lt;/li&gt;
      &lt;li&gt;查询数据并写入hive-hbase-table&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 16 Dec 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/hbase/2018/12/Hbase-%E6%B7%B1%E5%85%A5.html</link>
        <guid isPermaLink="true">http://localhost:4000/hbase/2018/12/Hbase-%E6%B7%B1%E5%85%A5.html</guid>
        
        <category>HBase</category>
        
        
        <category>Hbase</category>
        
      </item>
    
      <item>
        <title>[Hadoop]文件存储格式</title>
        <description>&lt;h3 id=&quot;rcfile&quot;&gt;RCFile&lt;/h3&gt;

&lt;p&gt;RCFile文件格式是FaceBook开源的一种Hive的文件存储格式，首先将表分为几个行组，对每个行组内的数据进行按列存储，每一列的数据都是分开存储，正是先水平划分，再垂直划分的理念。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/RFCile.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;数据部分我们可以看出RCFile将每一行，存储为一列，将一列存储为一行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/RCFile2.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而RCFile由于相同的列都是在一个HDFS块上，所以相对列存储而言会节省很多资源&lt;/p&gt;

&lt;h3 id=&quot;orcfile&quot;&gt;ORCFile&lt;/h3&gt;

&lt;p&gt;ORC的全称是(Optimized Row Columnar)，它并不是一个单纯的列式存储格式，仍然是首先根据行组分割整个表，在每一个行组内进行按列存储。&lt;/p&gt;

&lt;p&gt;ORC on hive优势：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;多个输出写到同一个文件上，减少namenode压力&lt;/li&gt;
  &lt;li&gt;文件是可切分（spilt）&lt;/li&gt;
  &lt;li&gt;提供了多种索引&lt;/li&gt;
  &lt;li&gt;支持复杂的数据结构&lt;/li&gt;
  &lt;li&gt;基于块压缩&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;orc-file-structure&quot;&gt;ORC file structure&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/OrcFileLayout.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;orc--parquet&quot;&gt;ORC &amp;amp; parquet&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/orc_and_parquet.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;列式存储压缩原理&quot;&gt;列式存储压缩原理&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/encoding.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;数据压缩算法&quot;&gt;数据压缩算法&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;delta-encoding 差分编码，增量编码
    &lt;ul&gt;
      &lt;li&gt;是通过储存差异来达到压缩的目标。&lt;/li&gt;
      &lt;li&gt;比如：
        &lt;ul&gt;
          &lt;li&gt;输入串：1000, 1001, 1002, 1005&lt;/li&gt;
          &lt;li&gt;压缩后：1000, 1, 2, 5&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;适用场景：有序数据集，例如timestamp&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;dictionary encoding 字典编码
    &lt;ul&gt;
      &lt;li&gt;提供一个字典，如果输入串中的单词&lt;strong&gt;命中&lt;/strong&gt;字典，则用字典中的位置来替换这个词。&lt;/li&gt;
      &lt;li&gt;适用场景：小规模的集合，例如IP地址&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;run length encoding 流程编码
    &lt;ul&gt;
      &lt;li&gt;用一个符号或串长代替具有相同值的连续符号&lt;/li&gt;
      &lt;li&gt;一个例子：
        &lt;ul&gt;
          &lt;li&gt;输入串：AAAAAAAAAAAAAAA AAAAAAAAAAAAAAA AAA&lt;/li&gt;
          &lt;li&gt;压缩后为：15A 15A 3A&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;适用场景：重复数据&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 16 Dec 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/hadoop/2018/12/Hadoop-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F.html</link>
        <guid isPermaLink="true">http://localhost:4000/hadoop/2018/12/Hadoop-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F.html</guid>
        
        <category>Hadoop</category>
        
        
        <category>Hadoop</category>
        
      </item>
    
      <item>
        <title>[Hadoop]安装方式</title>
        <description>&lt;h2 id=&quot;下载&quot;&gt;下载&lt;/h2&gt;

&lt;p&gt; 下载地址 &lt;code class=&quot;highlighter-rouge&quot;&gt;archive.apache.org/dist/hadoop/common/&lt;/code&gt; 
 相关文档&lt;code class=&quot;highlighter-rouge&quot;&gt;http://hadoop.apache.org/docs&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;linux相关配置&quot;&gt;Linux相关配置&lt;/h3&gt;

&lt;h5 id=&quot;1-yum源&quot;&gt;1. yum源&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1. 上传包含安装包的文件到节点
2. 安装httpd包
rpm -ivh  apr-1.4.8-3.el7.x86_64.rpm 
rpm -ivh  apr-util-1.5.2-6.el7.x86_64.rpm 
rpm -ivh  httpd-tools-2.4.6-40.el7.centos.x86_64.rpm 
rpm -ivh  mailcap-2.1.41-2.el7.noarch.rpm
rpm -ivh  httpd-2.4.6-40.el7.centos.x86_64.rpm
3. 启动httpd进程，并设置为开机启动
systemctl   start    httpd
systemctl   enable   httpd
4. 安装createrepo包，用来构建软件仓库
rpm -ivh  deltarpm-3.6-3.el7.x86_64.rpm 
rpm -ivh  python-deltarpm-3.6-3.el7.x86_64.rpm 
rpm -ivh  libxml2-python-2.9.1-5.el7_1.2.x86_64.rpm 
rpm -ivh  libxml2-2.9.1-5.el7_1.2.x86_64.rpm 
rpm -ivh  createrepo-0.9.9-23.el7.noarch.rpm 
5.创建软链接到硬盘中的包文件夹
http工作目录是/var/www/html/，需要设置一个目录指向包文件夹的地址
cd  /var/www/html/
mkdir  /var/www/html/CentOS7.2/
ln -s  /data01/Packages   /var/www/html/CentOS7.2/Packages
chmod 755 -R /var/www/html/CentOS7.2/Packages
6.使用上面安装的createrepo来创建仓库
createrepo  /var/www/html/CentOS7.2/Packages
7.关闭防火墙
setenforce 0 
systemctl   stop    firewalld
访问IP地址下的/CentOS7.2/Packages能看到包并可以下载就可以了。
8.所有主机都配置一下repo文件
文件夹地址在/etc/yum.repos.d/
1.备份原来的repo源文件
cd /etc/yum.repos.d/
mkdir  bak
mv CentOS-*.repo  bak/
2.创建自己的repo文件，写入内容
vi  base.repo

[base]
name=CentOS-Packages
baseurl=http://192.168.33.201/CentOS7.2/Packages/
gpgkey=
path=/
enabled=1
gpgcheck=0
3.清理yum缓存，重新构建缓存，测试安装一个包
yum clean all
yum makecache
yum list|grep vim（举个例子，把包里面有vim的包都列出来）
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;2-禁用selinux否则重启之后可能会无法访问到yum的软件库&quot;&gt;2. 禁用SELinux，否则重启之后可能会无法访问到yum的软件库&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1.setenforce 0	临时关闭SELinux
2.修改/etc/selinux/config中的SELINUX=disabled
	sed -i 's/^SELINUX=.*/SELINUX=disabled/g'   /etc/selinux/config
	sed -i 's/^SELINUX=.*/SELINUX=disabled/g'   /etc/sysconfig/selinux
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;3关闭thp影响hadoop集群的性能&quot;&gt;3.关闭THP（影响hadoop集群的性能）&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabled
echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/defrag
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;4修改swappiness&quot;&gt;4.修改swappiness&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;这个值表示剩余多少内存的时候使用磁盘，设置为0即最大限度的使用内存
echo &quot;vm.swappiness=0&quot; &amp;gt;&amp;gt; /etc/sysctl.conf 
sysctl -p    ##让配置生效
cat /proc/sys/vm/swappiness
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;5修改主机名配置主机名文件ssh免密登陆&quot;&gt;5.修改主机名，配置主机名文件，ssh免密登陆&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1.修改主机名
	hostnamectl --static set-hostname hadoop1
2.配置主机名文件
	vi /etc/hosts
3.关闭防火墙即开机关闭
	systemctl stop firewalld.service
	systemctl disable firewalld.service
4.配置ssh免密登陆
	ssh-keygen
	ssh-copy-id 主机名

远程复制:
1. 复制文件（本地&amp;gt;&amp;gt;远程：scp /cloud/data/test.txt root@10.21.156.6:/cloud/data/
2. 复制文件（远程&amp;gt;&amp;gt;远程：scp root@10.21.156.6:/cloud/data/test.txt /cloud/data/
3. 复制目录（本地&amp;gt;&amp;gt;远程：scp -r /cloud/data root@10.21.156.6:/cloud/data/
4. 复制目录（远程&amp;gt;&amp;gt;本地：scp -r root@10.21.156.6:/cloud/data/ /cloud/data
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;6设置时区统一时间&quot;&gt;6.设置时区，统一时间&lt;/h5&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1.所有节点设置时区：
timedatectl set-timezone &quot;Asia/Shanghai&quot;
2.统一时间，“对表”，即以主节点的时间为准
1.所有机器安装ntp
	yum -y install ntp
2.修改主节点配置文件，所有机器时间以主节点（如hadoop1）时间为准，
	1.所有节点备份原始配置文件
		cp /etc/ntp.conf /etc/ntp.conf.bak
	2.修改主节点hadoop1配置
		vi /etc/ntp.conf
			# server 0.centos.pool.ntp.org iburst
			# server 1.centos.pool.ntp.org iburst
			# server 2.centos.pool.ntp.org iburst
			# server 3.centos.pool.ntp.org iburst 
			server 127.127.1.1
	3.重启ntpd进程，设置开机自启
		systemctl restart ntpd
		systemctl enable ntpd
3.在其他节点上指定以hadoop1为准来进行时间校准
	ntpdate hadoop1
	systemctl start ntpd
	crontab	定时执行脚本/命令
4.修改其他节点上的配置文件（同主节点修改步骤）
	vi /etc/ntp.conf
		# server 0.centos.pool.ntp.org iburst
		# server 1.centos.pool.ntp.org iburst
		# server 2.centos.pool.ntp.org iburst
		# server 3.centos.pool.ntp.org iburst 
		server 192.168.33.201
5.其他节点上重启ntpd进程，并设置成开机自启
	systemctl restart ntpd
	systemctl enable ntpd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;hadoop相关&quot;&gt;Hadoop相关&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;安装jdk
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;JAVA_HOME
CDH中spark会默认到/usr/java/default目录下去找jdk，所以一般就安装在/usr/java目录下
export JAVA_HOME=/usr/java/jdk1.8.0_25
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export PATH=$JAVA_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;解压到指定目录&lt;/li&gt;
  &lt;li&gt;修改配置文件
```
1.配置jdk的地址，etc/hadoop/hadoop-env.sh文件
 # set to the root of your Java installation
 export JAVA_HOME=/usr/java/latest&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;standalone本地运行的操作
	  $ mkdir input
	  $ cp etc/hadoop/&lt;em&gt;.xml input
	  $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar wordcount input output
	  $ cat output/&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;2.配置hdfs，etc/hadoop/core-site.xml文件
新建文件夹data/tmp，用来存放临时文件&lt;/p&gt;
&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;fs.defaultFS&lt;/name&gt;
		## 指定了namenode的节点
		&lt;value&gt;hdfs://hadoop1:9001&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
		&lt;value&gt;/opt/modules/hadoop-2.7.7/data/tmp&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;etc/hadoop/hdfs-site.xml文件，配置副本数
&amp;lt;configuration&amp;gt;
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
	# python操作hdfs时需要获取权限
	&amp;lt;property&amp;gt; 
		&amp;lt;name&amp;gt;dfs.permissions&amp;lt;/name&amp;gt; 
		&amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt; 
	&amp;lt;/property&amp;gt;
	## 指定secondarynamenode节点
	&amp;lt;property&amp;gt;
		&amp;lt;name&amp;gt;dfs.namenode.secondary.http-address&amp;lt;/name&amp;gt;
		&amp;lt;value&amp;gt;节点地址:50090&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;

3.首次启动，namenode需要格式化
	bin/hdfs namenode -format
	
hdfs的web监控端口是50070
		
4.配置yarn
etc/hadoop/mapred-site.xml文件
	&amp;lt;configuration&amp;gt;
		&amp;lt;property&amp;gt;
			&amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
			&amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
		&amp;lt;/property&amp;gt;
		## 配置historyserver
		&amp;lt;property&amp;gt;
			&amp;lt;name&amp;gt;mapreduce.jobhistory.address&amp;lt;/name&amp;gt;
			&amp;lt;value&amp;gt;节点主机名:10020&amp;lt;/value&amp;gt;
		&amp;lt;/property&amp;gt;
		&amp;lt;property&amp;gt;
			&amp;lt;name&amp;gt;mapreduce.jobhistory.webapp.address&amp;lt;/name&amp;gt;
			&amp;lt;value&amp;gt;节点主机名:19888&amp;lt;/value&amp;gt;
		&amp;lt;/property&amp;gt;
	&amp;lt;/configuration&amp;gt;

etc/hadoop/yarn-site.xml文件
	&amp;lt;configuration&amp;gt; 
    	&amp;lt;property&amp;gt;
    		&amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
    		&amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
    	&amp;lt;/property&amp;gt;
    	## 指定resourcemanager节点
    	&amp;lt;property&amp;gt;
    		&amp;lt;name&amp;gt;yarn.resourcemanager.hostname&amp;lt;/name&amp;gt;
    		&amp;lt;value&amp;gt;主节点的hostname&amp;lt;/value&amp;gt;
    	&amp;lt;/property&amp;gt;
		## 日志聚集功能开启
		&amp;lt;property&amp;gt;
			&amp;lt;name&amp;gt;yarn.log-aggregation-enable&amp;lt;/name&amp;gt;
			&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
		&amp;lt;/property&amp;gt;
		## 日志文件保存的时间，以秒为单位
		&amp;lt;property&amp;gt;
			&amp;lt;name&amp;gt;yarn.log-aggregation.retain-seconds&amp;lt;/name&amp;gt;
			&amp;lt;value&amp;gt;640800&amp;lt;/value&amp;gt;
		&amp;lt;/property&amp;gt;
	&amp;lt;/configuration&amp;gt;
		
slaves: 指定启动的脚本，如启动start-dfs.sh
	指定datanode和nodemanager是哪些节点
yarn的web监控端口是8088
		
5.配置文件的类别
	1.默认配置文件:四个模块相对应的jar中，$HADOOP_HOME/share/hadoop/...
		core-default.xml
		hdfs-default.xml
		yarn-default.xml
		mapred-default.xml
	2.自定义配置文件，$HADOOP_HOME/etc/hadoop/
		core-site.xml
		hdfs-site.xml
		yarn-site.xml
		mapred-site.xml
		
6.启动方式
	1.各个节点服务组件逐一启动
		hadoop-daemon.sh start namenode
		hadoop-daemon.sh start datanode
		sbin/mr-jobhistory-daemon.sh start historyserver
	2.各个模块统一启动
		hadoop1:start-dfs.sh
		hadoop2:start-yarn.sh	mr-jobhistory-daemon.sh start historyserver
			
	3.所有节点服务统一启动
		start-all.sh（不建议使用）
		因为一般实际情况下namenode和resourcemanager不建议配置在一台机器上

7.查看安全模式
	hdfs dfsadmin -safemode get
	
8.其他
	yarn默认的配置，cpu有8核，内存为8G，可以配置
		
	apache slider 动态的yarn
		把已经存在的分布式框架运行在yarn上
	
9.mr
	以wordcount为例：
	map：映射，可以高度并行
		输入输出形式都是键值对
			输入的key，value对，key为字符偏移量，value为字符串类型
			
	reduce：合并
	
	mapreduce优化
		1.reduce的个数，job.reduces 默认为1个
		2.shuffle过程的compress和combiner
		3.shuffle的各种参数调节 ```
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上传到工作目录:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hdfs dfs -put /etc/profile /file
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;参考：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hadoop.apache.org/docs/r2.9.2/&quot;&gt;Hadoop官方文档&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Dec 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/hadoop/2018/12/Hadoop-%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F.html</link>
        <guid isPermaLink="true">http://localhost:4000/hadoop/2018/12/Hadoop-%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F.html</guid>
        
        <category>Hadoop</category>
        
        
        <category>Hadoop</category>
        
      </item>
    
  </channel>
</rss>
