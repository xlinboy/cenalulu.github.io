```
# Please paste flume.conf here. Example:

# Sources, channels, and sinks are defined per
# agent name, in this case 'tier1'.
tier1.sources  = source1
tier1.channels = channel1
tier1.sinks    = sink1

# For each source, channel, and sink, set
# standard properties.
# tier1.sources.source1.type = netcat
tier1.sources.source1.type = exec
tier1.sources.source1.bind = hadoop1
tier1.sources.source1.port = 9999
tier1.sources.source1.command = tail -F /tmp/root/hive.log

tier1.sources.source1.channels = channel1
tier1.sinks.sink1.channel = channel1

# tier1.sinks.sink1.type = logger

tier1.sinks.sink1.type = hdfs
tier1.sinks.sink1.hdfs.path = /user/root/flume

tier1.sinks.sink1.hdfs.filePrefix = events-
tier1.sinks.sink1.hdfs.rollInterval = 60
tier1.sinks.sink1.hdfs.rollSize = 102400
tier1.sinks.sink1.hdfs.rollCount = 1000000
tier1.sinks.sink1.hdfs.batchSize = 100
tier1.sinks.sink1.hdfs.maxOpenFiles = 5000
tier1.sinks.sink1.hdfs.idleTimeout = 0
tier1.sinks.sink1.hdfs.fileType = DataStream

# Other properties are specific to each type of
# source, channel, or sink. In this case, we
# specify the capacity of the memory channel.

tier1.channels.channel1.type = memory
tier1.channels.channel1.capacity = 1000
tier1.channels.channel1.transactionCapacity = 1000

```

### Spooling Directory Source

1. 监控目录
2. FileChannel
3. HDFS Store

![image](https://xlactive-1258062314.cos.ap-chengdu.myqcloud.com/spooling.png)