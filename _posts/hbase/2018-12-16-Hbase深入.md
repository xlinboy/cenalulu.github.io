---
layout: article
title:  "Hbase的指令操作及预分区"
categories: hbase
date:   2018-12-18 08:44:13
tags: hbase base grammer
---

### 1. shell 创建表的多种形式

注意命名空间、多个列簇及属性  
```
Create a table with namespace=ns1 and table qualifier=t1
	hbase> create 'ns1:t1', {NAME => 'f1', VERSIONS => 5}
	
	Create a table with namespace=default and table qualifier=t1
	hbase> create 't1', {NAME => 'f1'}, {NAME => 'f2'}, {NAME => 'f3'}
	hbase> # The above in shorthand would be the following:
	hbase> create 't1', 'f1', 'f2', 'f3'
	hbase> create 't1', {NAME => 'f1', VERSIONS => 1, TTL => 2592000, BLOCKCACHE => true}
	hbase> create 't1', {NAME => 'f1', CONFIGURATION => {'hbase.hstore.blockingStoreFiles' => '10'}}
```
### 2. 预分区
table 逻辑上的分区，以行的形式存储
```
    region 
    startkey, endkey
```
- 默认情况下，创建表hbase表会自动为表分区
- 一般情况下，创建好表之后，会导入大量数据
    ```
    file/data -> file -> bulk load
    
    region -> managed regionserver
		|
		|
		split -> two region
		|
		|
		regionserver负载大
    ```
	所以，一般会在创建表的时候就创建多个region，依据表的rowkey进行设计，结合业务
- 如何预先创建多个region？ **hbase表的预分区**
- region划分依赖rowkey，预估rowkey的划分准则


region划分依赖rowkey，预估rowkey的划分准则
```
hbase> create 'ns1:t1', 'f1', SPLITS => ['10', '20', '30', '40']
hbase> create 'h_work', 'info', SPLITS => ['001', '002', '003', '004','007','015','050','100','150','200','250','300']
hbase> create 't1', 'f1', SPLITS_FILE => 'splits.txt', OWNER => 'johndoe'
hbase> create 't1', {NAME => 'f1', VERSIONS => 5}, METADATA => { 'mykey' => 'myvalue' }
hbase> # Optionally pre-split the table into NUMREGIONS, using
hbase> # SPLITALGO ("HexStringSplit", "UniformSplit" or classname)
hbase> create 't1', 'f1', {NUMREGIONS => 15, SPLITALGO => 'HexStringSplit'}
hbase> create 't1', 'f1', {NUMREGIONS => 15, SPLITALGO => 'HexStringSplit', REGION_REPLICATION => 2, CONFIGURATION => {'hbase.hregion.scan.loadColumnFamiliesOnDemand' => 'true'}}
hbase> create 't1', {NAME => 'f1', DFS_REPLICATION => 1}
```
如：
1. create 'logs','info',SPLITS => ['20181010','20181020','20181030']
2. 指定分隔文件
	create 'logs','info',SPLITS => 'opt/datas/logs_split.txt'
3. 指定多少分区，十六进制字符串分割
	create 't1', 'f1', {NUMREGIONS => 3, SPLITALGO => 'HexStringSplit'}

### 表属性
查看一张表的属性，describe 'user'
```
COLUMN FAMILIES DESCRIPTION                                                     
{
NAME => 'info', 
BLOOMFILTER => 'ROW',  布隆过滤器
VERSIONS => '1', 
IN_MEMORY => 'false', 
KEEP_DELETED_CELLS => 'FALSE', 
DATA_BLOCK_ENCODING => 'NONE', 	
TTL => 'FOREVER', 
COMPRESSION => 'NONE', 	压缩属性
	hadoop checknative查看当前hadoop支持哪些压缩
MIN_VERSIONS => '0', 
BLOCKCACHE => 'true', 
BLOCKSIZE => '65536', 
REPLICATION_SCOPE => '0'
}
```

#### 1. 压缩属性
配置hbase的snappyd压缩
1. 配置hadoop 的压缩配置
2. 配置hbase
    - hadoop-snappy-0.0.1-SNAPSHOT.jar放到hbase的lib下
	- 需要将本地的库native内容放到hbase的lib下的native目录下

创建软连接即可
```
ln -s $HADOOP_HOME/lib/native $HBASE_HOME/lib/native/Linux-amd64-64
```
然后创建表的时候，可以指定d压缩属性。

需要强制告诉regionserver，配置hbase.regionserver.codecs的value为snappy，且重启regionserver生效  


**但是如果原表里面已经有了很多数据，那么压缩是不会生效的**

#### 2. regionserver的内存
- memstore 40%
- blockcache 40%，块缓存每个regionserver只有一个blockcache
- other

客户端读取数据会从三个地方读取数据，按顺序读取
1. memstore
2. blockcache
3. hfile
然后进行merge合并，返回数据集。

##### cache的等级
- immemory:0.25, 即缓存数据放在不轻易删除的内存中，如meta元数据信息。`describe 'inmemory'`
- multi:0.50, 即比较重要的数据
- single:0.25, 即可以缓存也可以不缓存的信息，最少使用的会加入到淘汰算法


### 表的compaction
- minor合并:多个小文件合并成多个大文件，即多路归并，受磁盘IO影响。 
- major合并，将一个region中的一列簇的所有hfile重写为一个新的hfile。扫描所有的键值对，顺序重写全部的数据。重写数据过程，略过做了删除标记的数据，以及超出版本号限制的数据。
- 重量级合并：阻塞所有的region的请求，有时间限制 ，直到合并完毕。小心死循环

### HBase+Hive/impala

`https://cwiki.apache.org/confluence/display/hive/hbaseintegration`
1. 数据存储在HBase
2. 表的描述信息存储在hive中
    hive从0.9.0版本才开始支持与HBase集成
3. 集成方式
  1. 管理表

    	创建hive表的时候，指定数据存储在hbase表中
  2. 外部表

    	现在已经存在了一个hbase表，需要对表中的数据进行分析
  4. 本质

    	hive就是hbase的客户端，需要jar包以及配置
    	```
    
       1.需要将hbase的依赖jar拷贝到hive/lib下
  	包括
  		hbase-common....
  		hbase-server....
  		hbase-client....
  		hbase-protocol....
  		hbase-it-....
  		hbase-hadoop-compat-....
  		hbase-hadoop2-compat-....
  		high-scale-lib-....
  		htrace-core-....
  		zookeeper-....
  		guave-...
  		版本要一致，以hbase版本为准
  		
  	2.在hive-site.xml文件中，添加zookeeper参数
  		hbase.zookeeper.quorum
  		hadoop1,hadoop2,hadoop3
​     ```
  4. 创建一张hive管理表
       ```	
       CREATE TABLE hbase_table_1(key int, value string) 
       STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
       WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf1:val")
       TBLPROPERTIES ("hbase.table.name" = "xyz", "hbase.mapred.output.outputtable" = "xyz");
       
       建表之后，查看表的描述信息
       hive> desc formatted hbase_table_1;
       hbase> describe 'xyz'
       
       使用hive语句导入数据
       hbase> scan 'xyz'
       ```

  5. 外部表
        即把已有的hbase表映射到hive的表
          	
           CREATE EXTERNAL TABLE hbase_table_2(key int, value string) 
           STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
           WITH SERDEPROPERTIES ("hbase.columns.mapping" = "cf1:val")
           TBLPROPERTIES("hbase.table.name" = "some_existing_table", "hbase.mapred.output.outputtable" = "some_existing_table");

  6. 应用场景
        - 有时候的数据迁移也是用这种方法
        - 如日志文件保存到hbase表
        - 导入hive表，使用列分割全表数据
        - 查询数据并写入hive-hbase-table